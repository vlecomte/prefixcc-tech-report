\documentclass[a4paper,10pt]{article}
\usepackage{mystyle}
\usepackage[top=3cm, bottom=3cm, left=3cm, right=3cm]{geometry}
\def\labelitemi{---}

\lstset{
    %basicstyle=\ttfamily,
    language=Python,
    frame=single,
    numbers=left,
    breaklines=true,
}

\begin{document}

\title{\texttt{PrefixCCFWC}: technical report}
\author{Victor Lecomte}
\maketitle

\begin{abstract}
In scheduling, it may be useful to specify cardinality constraints on certain prefixes of an array of variables. For example, if only one item can be produced each day, and you have to deliver 3 units of product $A$ after 7 days, you will want to impose that there be at least 3 occurences of $A$ among the production variables for the first 7 days.

This constraint allows you to apply many such constraints on several values without the overhead of creating a GCC for each of them, and with some additional pruning.
\end{abstract}

\tableofcontents

\section{Problem statement}
We are given an array of integer variables and a number of constraints of the form:
\begin{quote}
There should be at least/most $b$ occurrences of value $v$ among the $i$ first variables.
\end{quote}
In scheduling this will mostly be lower bounds coming from quantities to be produced at a certain date, but there could also be upper bounds coming from storage limitations.

For example let's consider four variables with values either \texttt{A} or \texttt{B}, and the following constraints:
\begin{itemize}
    \item there should be at least one \texttt{B} in the first two variables ($b=1$, $v=\texttt{B}$, $i=2$);
    \item there should be at most two \texttt{A}s in all the variables ($b=2$, $v=\texttt{A}$, $i=4$).
\end{itemize}
Then the following results would be valid:
\begin{itemize}
    \item \texttt{A B A B}
    \item \texttt{B B B B}
\end{itemize}
While the following results would be invalid:
\begin{itemize}
    \item \texttt{A A B B} (no \texttt{B} in the first two variables)
    \item \texttt{B A A A} (too many \texttt{A}s)
\end{itemize}

\section{The algorithm}
The algorithm consists of two main parts:
\begin{enumerate}
    \item The deduction and filtering of the bounds, where we analyze the bounds given to filter out the redundant ones and add additional ones when possible.
    \item The propagation, which takes the bounds obtained in the first part and applies pruning identical to regular forward-checking GCC, but in an efficient unified manner.
\end{enumerate}

We will start by explaining the \emph{bound deduction} (\ref{subsec:deduction}) and \emph{bound filtering} (\ref{subsec:filtering}) steps, then we will introduce the concept of \emph{critical values} (\ref{subsec:critical}) and how it is the key in unifying the bound checking, and finally we will go on to the \emph{merging and pruning process} (\ref{subsec:merging-pruning}), the main propagation mechanism.

\subsection{Bound deduction}
\label{subsec:deduction}

The deduction step aims to obtain better bounds for the occurrences of a value than those given in the input, based on two factors:
\begin{itemize}
    \item the values of the bounds on the same value for other prefixes, ``inter-prefix'';
    \item the values of the opposite bounds for the same prefix on other values, ``inter-value''.
\end{itemize}

\subsubsection{Inter-prefix deduction}

The first factor is based on these four types of deduction:
\begin{itemize}
    \item if there are at least three \texttt{A}s in the first five variables, there are also at least three \texttt{A}s in the first six variables (I), and at least \emph{two} in the first four (because we are only possibly removing one) (II);
    \item if there are at most three \texttt{A}s in the first five variables, there are also at most three \texttt{A}s in the first four variables (III), and at most \emph{four} in the first six (because we are only possibly adding one) (IV).
\end{itemize}

In practice, those deductions can be made by maintaining an array of the best known bounds for each prefix and then traversing once forwards for deductions (I) and (IV) and once backwards for deductions (II) and (III).

Here is a pseudocode, for a certain value:
\begin{lstlisting}
for i in 1 to (numberOfVariables-1):
    lower(i) = max(lower(i), lower(i-1))
    upper(i) = min(upper(i), upper(i-1) + 1)
for i in (numberOfVariables-2) to 0:
    lower(i) = max(lower(i), lower(i+1) - 1)
    upper(i) = min(upper(i), upper(i+1))
\end{lstlisting}

\subsubsection{Inter-value deduction}

The second factor is based on these two types of deduction:
\begin{itemize}
    \item in the first five variables, if the minimal number of occurrences for all the other values is three, then we can decrease the maximal number of occurrences for this value to two (since there are at most for five occurences in total);
    \item in the first five variables, if the maximal number of occurrences for all the other values is three, then we can increase the minimal number of occurrences for this value to two (since there are at least five occurrences in total).
\end{itemize}

In practice, those deductions can be made for each prefix and for each value by computing the sums of all the lower (resp. upper) bounds for all of the other values and setting the upper (resp. lower) bound of this value to the length of the prefix minus that sum (if this results in a stronger bound).

Here is a pseudocode, for a certain prefix:
\begin{lstlisting}
for v in values:
    lower(v) = max(lower(v), sizeOfPrefix - (sum(upper) - upper(v)))
    upper(v) = min(upper(v), sizeOfPrefix - (sum(lower) - lower(v)))
\end{lstlisting}

\subsection{Bound filtering}
\label{subsec:filtering}

Once the algorithm has deduced the best bounds it could, one would like to filter them and only keep those that add information. This step sounds a lot like applying the inter-prefix deduction in reverse: instead of creating new bounds by deducing them from the next or previous prefix, we will remove them if they can be deduced in that way.

In practice, we will traverse the prefixes from left to right, and:
\begin{enumerate}
    \item only add a bound if it gives more information than the previous bound;
    \item remove the previous bounds that can be deduced from the bound we're adding.
\end{enumerate}

That second point is similar in spirit with the ``monotone chain'' algorithm for convex hulls: we're trying to find a minimal set of bounds (resp. points) and to ensure it's minimal, when adding a new bound (resp. point), we remove the previous bounds (resp. points) as long as they're being made useless by the new one.

For lower bounds, we base ourselves on the inter-prefix deduction laws (see \ref{subsec:deduction}) in this way:
\begin{itemize}
    \item a bound only adds information if it is higher than the previous one (I);
    \item a previous bound has to be removed if it is lower or equal to the new bound \emph{minus their distance} (II).
\end{itemize}

For example, if we have a lower bound of one on the first three variables, we can add a lower bound of three on the first five variables, because it adds informations. However, we will then have to remove the previous constraint, because that lower bound of one can be directly deduced from the one we're adding.

In general, we can visually check if a lower bound is stronger than another by ``extending'' it, decreasing constantly on the left and staying constant on the right, like this: \textbf{TODO: insert diagram}

Here is a pseudocode of the filtering for lower bounds:
\begin{lstlisting}
for cur in lowerBounds:
    if cur.bound > last.bound:
        while last.bound <= cur.bound - (cur.index - last.index):
            removeLast()
        add(cur)
\end{lstlisting}

The situation is similar for upper bounds:
\begin{itemize}
    \item a bound only adds information if it is lower than the previous one \emph{plus their distance} (IV);
    \item a previous bound has to be removed if it is higher or equal to the new bound (III).
\end{itemize}

The ``extension'' works in the same way: \textbf{TODO: insert diagram}

Here is a pseudocode of the filtering for upper bounds:
\begin{lstlisting}
for cur in upperBounds:
    if cur.bound < last.bound + (cur.index - last.index):
        while last.bound >= cur.bound
            removeLast()
        add(cur)
\end{lstlisting}

\subsection{The concept of critical values}
\label{subsec:critical}

Now that we have obtained an optimal set of bounds, we have to figure out how to quickly check on an update whether a bound has reached its objective: we want to know when the number of variables that have a value reaches the lower bound, so that we can assign them all; or when the number of variables that are bound to the value reaches the upper bound, so that we can remove the value from all the other variables.

The issue is that a variable may be included in many prefixes with a lower bound or an upper bound, and checking every single one of them could take time. We have to find a way to do it only once.

In order to do that, we divide the variables into segments separated by the bounds.

For example, if for some value we have an upper bound of 2 for the prefix $[0,3[$ and an upper bound of 5 for the prefix $[0,8[$, we will separate the variables into the segments $[0,3[$ and $[3,8[$. We will examine the differences between the bounds. If in the segment $[3,8[$ the number of variables assigned to the value reaches $5-2=3$, that means there will be at least 3 occurrences of the value in that segment. As a consequence, if the upper bound of 2 in the prefix $[0,3[$ fails, it means there will be more than 2 occurrences of the value in $[0,3[$ and thus more than 5 occurrences of the value in $[0,8[$, which makes the upper bound of 5 in the prefix $[0,8[$ fail as well. This means that the upper bound for $[0,3[$ does not add any information anymore, and we can eliminate it.

We will name this difference $5-2=3$ the \emph{critical value} for that segment. It means that when the number of variables assigned to the value in the segment reaches that value, we can eliminate the bound on the left of the segment. On updates, our only job will be to check whether we reached the critical value, and trigger actions if that is the case.

The critical value also makes sense for lower bounds: if this time we take a \emph{lower} bound of 2 for $[0,3[$ and a \emph{lower} bound of 5 for $[0,8[$, imagine that the number of variables that have the value in the segment (bound or not) decreases to 3, there will be at most 3 occurrences of the value in that segment. If the lower bound in the prefix $[0,3[$ fails, then there will be less than 2 occurrences of the value in $[0,3[$ and thus less than 5 occurrences in $[0,8[$, which makes the lower bound in the prefix $[0,8[$ fail as well. This means that the lower bound for $[0,3[$ does not add any information anymore, and we can eliminate it.

\subsection{Merging and pruning}
\label{subsec:merging-pruning}
\textbf{TODO}

\section{Complexity}
\textbf{TODO}

\section{Conclusion and use cases}
\textbf{TODO}

\end{document}
